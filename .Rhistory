#Task 2
#=======================================
set.seed(100)
training.idx = sample(1:nrow(marketing), size = nrow(marketing) * 0.8)
train.data = marketing[training.idx,]
test.data = marketing[-training.idx,]
#=======================================
#Task 3
#=======================================
#kNN method:
model = train(sales~., data=train.data, method='knn', trControl=trainControl('cv',number =4), preProcess=c('center','scale'),tuneLength=10)
plot(model)
model$bestTune #best number of k such that RMSE is lowest
predictions = predict(model, test.data)
head(predictions)
RMSE(predictions, test.data$sales)
plot(test.data$sales, predictions, main="Prediction performance of kNN regression")
abline(0,1,col='red')
#linear regression method:
lmodel = lm(sales~., data=train.data)
summary(lmodel) #newspaper is less related to sales
predictions = predict(lmodel,test.data)
plot(test.data$sales,predictions, main="Prediction performance of linear regression")
abline(0,1,col='red')
RMSE(predictions, test.data$sales)
#=======================================
#Task 4
#=======================================
par(mfrow = c(2,2))
plot(lmodel) #it can be improved since it is not linear and there exist an outlier #131
par(mfrow=c(1,1))
#=======================================
#Task 5 (Goal to obtain smaller value for RMSE)
#=======================================
#Method 1: remove outlier 131
marketing1 = marketing[-131,]
training.idx = sample(1:nrow(marketing1), size = nrow(marketing1) * 0.8)
train.data = marketing1[training.idx,]
test.data = marketing1[-training.idx,]
lmodel = lm(sales~., data=train.data)
summary(lmodel) #newspaper is less related to sales
predictions = predict(lmodel,test.data)
plot(test.data$sales,predictions, main="Prediction performance of linear regression")
abline(0,1,col='red')
RMSE(predictions, test.data$sales)
#Method 2: adding second order terms
training.idx = sample(1:nrow(marketing), size = nrow(marketing) * 0.8)
train.data = marketing[training.idx,]
test.data = marketing[-training.idx,]
lmodel2 = lm(sales~youtube + facebook + newspaper + I(youtube^2) + I(youtube*newspaper) + I(newspaper^2) + I(youtube*facebook) + I(facebook^2), data = train.data)
summary(lmodel2)
predictions = predict(lmodel2, test.data)
RMSE(predictions, test.data$sales)
#Method 3: remove outlier 131 and adding second order terms
marketing3 = marketing[-131,]
training.idx = sample(1:nrow(marketing1), size = nrow(marketing1) * 0.8)
train.data = marketing1[training.idx,]
test.data = marketing1[-training.idx,]
lmodel3 = lm(sales~youtube + facebook + newspaper + I(youtube^2) + I(youtube*newspaper) + I(newspaper^2) + I(youtube*facebook) + I(facebook^2), data = train.data)
summary(lmodel3)
predictions = predict(lmodel3, test.data)
RMSE(predictions, test.data$sales)
#=======================================
#Task 1
#=======================================
summary(marketing)
dim(marketing)
head(marketing)
str(marketing)
boxplot(marketing$sales)
pairs.panels(marketing,main = 'Marketing methods and sales',method = "pearson", hist.col =  "steelblue",
pch = 21, density = TRUE, ellipses = FALSE)
#we get Pearson correlation coefficient
#we found out that youtube and sales are highly and linearly related
#followed by facebook and sales, facebook and newspaper
#method 2
corrplot(cor(marketing),type="upper",method="color",addCoef.col = "black",number.cex = 0.6)
#=======================================
#Task 2
#=======================================
set.seed(100)
training.idx = sample(1:nrow(marketing), size = nrow(marketing) * 0.8)
train.data = marketing[training.idx,]
test.data = marketing[-training.idx,]
#=======================================
#Task 3
#=======================================
#kNN method:
model = train(sales~., data=train.data, method='knn', trControl=trainControl('cv',number =4), preProcess=c('center','scale'),tuneLength=10)
plot(model)
model$bestTune #best number of k such that RMSE is lowest
predictions = predict(model, test.data)
head(predictions)
RMSE(predictions, test.data$sales)
plot(test.data$sales, predictions, main="Prediction performance of kNN regression")
abline(0,1,col='red')
#=======================================
#Task 1
#=======================================
summary(marketing)
dim(marketing)
head(marketing)
str(marketing)
boxplot(marketing$sales)
pairs.panels(marketing,main = 'Marketing methods and sales',method = "pearson", hist.col =  "steelblue",
pch = 21, density = TRUE, ellipses = FALSE)
#we get Pearson correlation coefficient
#we found out that youtube and sales are highly and linearly related
#followed by facebook and sales, facebook and newspaper
#method 2
corrplot(cor(marketing),type="upper",method="color",addCoef.col = "black",number.cex = 0.6)
#=======================================
#Task 2
#=======================================
set.seed(100)
training.idx = sample(1:nrow(marketing), size = nrow(marketing) * 0.8)
train.data = marketing[training.idx,]
test.data = marketing[-training.idx,]
#=======================================
#Task 3
#=======================================
#kNN method:
model = train(sales~., data=train.data, method='knn', trControl=trainControl('cv',number =4), preProcess=c('center','scale'),tuneLength=10)
plot(model)
model$bestTune #best number of k such that RMSE is lowest
predictions = predict(model, test.data)
head(predictions)
RMSE(predictions, test.data$sales)
plot(test.data$sales, predictions, main="Prediction performance of kNN regression")
abline(0,1,col='red')
#linear regression method:
lmodel = lm(sales~., data=train.data)
summary(lmodel) #newspaper is less related to sales
predictions = predict(lmodel,test.data)
plot(test.data$sales,predictions, main="Prediction performance of linear regression")
abline(0,1,col='red')
RMSE(predictions, test.data$sales)
#=======================================
#Task 4
#=======================================
par(mfrow = c(2,2))
plot(lmodel) #it can be improved since it is not linear and there exist an outlier #131
par(mfrow=c(1,1))
#Method 3: remove outlier 131 and adding second order terms
marketing3 = marketing[-131,]
training.idx = sample(1:nrow(marketing1), size = nrow(marketing1) * 0.8)
train.data = marketing1[training.idx,]
test.data = marketing1[-training.idx,]
lmodel3 = lm(sales~youtube + facebook + newspaper + I(youtube^2) + I(youtube*newspaper) + I(newspaper^2) + I(youtube*facebook) + I(facebook^2), data = train.data)
summary(lmodel3)
predictions = predict(lmodel3, test.data)
RMSE(predictions, test.data$sales)
#Method 3: remove outlier 131 and adding second order terms
marketing3 = marketing[-131,]
training.idx = sample(1:nrow(marketing1), size = nrow(marketing1) * 0.8)
train.data = marketing1[training.idx,]
test.data = marketing1[-training.idx,]
lmodel3 = lm(sales~youtube + facebook + newspaper + I(youtube^2) + I(newspaper^2) + I(facebook^2), data = train.data)
summary(lmodel3)
predictions = predict(lmodel3, test.data)
RMSE(predictions, test.data$sales)
#Method 3: remove outlier 131 and adding second order terms
marketing3 = marketing[-131,]
training.idx = sample(1:nrow(marketing1), size = nrow(marketing1) * 0.8)
train.data = marketing1[training.idx,]
test.data = marketing1[-training.idx,]
lmodel3 = lm(sales~youtube + facebook + newspaper + I(youtube^2) + I(facebook^2), data = train.data)
summary(lmodel3)
predictions = predict(lmodel3, test.data)
RMSE(predictions, test.data$sales)
#Method 3: remove outlier 131 and adding second order terms
marketing3 = marketing[-131,]
set.seed(100)
training.idx = sample(1:nrow(marketing1), size = nrow(marketing1) * 0.8)
train.data = marketing1[training.idx,]
test.data = marketing1[-training.idx,]
lmodel3 = lm(sales~youtube + facebook + newspaper + I(youtube^2) + I(facebook^2), data = train.data)
summary(lmodel3)
predictions = predict(lmodel3, test.data)
RMSE(predictions, test.data$sales)
#Method 3: remove outlier 131 and adding second order terms
marketing3 = marketing[-131,]
set.seed(100)
training.idx = sample(1:nrow(marketing1), size = nrow(marketing1) * 0.8)
train.data = marketing1[training.idx,]
test.data = marketing1[-training.idx,]
lmodel3 = lm(sales~youtube + facebook + newspaper + I(youtube^2) + I(facebook^2) + I(youtube*facebook), data = train.data)
summary(lmodel3)
predictions = predict(lmodel3, test.data)
RMSE(predictions, test.data$sales)
summary(lmodel3)
#Method 3: remove outlier 131 and adding second order terms
marketing3 = marketing[-131,]
set.seed(100)
training.idx = sample(1:nrow(marketing1), size = nrow(marketing1) * 0.8)
train.data = marketing1[training.idx,]
test.data = marketing1[-training.idx,]
lmodel3 = lm(sales~youtube + facebook + newspaper + I(youtube^2) + I(facebook^2) + I(youtube*facebook) + I(newspaper*facebook), data = train.data)
summary(lmodel3)
predictions = predict(lmodel3, test.data)
RMSE(predictions, test.data$sales)
summary(lmodel3)
#MH3511 Lab 6 Solution
#=======================================
#Exercise 6.1
#=======================================
#a
prop.test(x=17, n=23, conf.level=0.95)
print(paste("width of CI is" 0.8891655-0.5131213))
print(paste("width of CI is", 0.8891655-0.5131213))
#b
prop.test(x=17, n=23, conf.level=0.80)
print(paste("Width of CI is", 0.8549674-0.5857604))
#c
prop.test(x=170, n=230, conf.level=0.95)
print(paste("Width of CI is", 0.7936082-0.6764982))
#d
prop.test(x=11, n=23, conf.level=0.95)
#e
prop.test(x=1, n=23, conf.level=0.95)
print(paste("Width of CI is", 0.239677815-0.002273764))
0.239677815
#MH3511 Lab 6 Solution
#=======================================
#Exercise 6.1
#=======================================
#a
prop.test(x=17, n=23, conf.level=0.95)
print(paste("Width of CI is", 0.8891655-0.5131213))
#b
prop.test(x=17, n=23, conf.level=0.80)
print(paste("Width of CI is", 0.8549674-0.5857604))
#c
prop.test(x=170, n=230, conf.level=0.95)
print(paste("Width of CI is", 0.7936082-0.6764982))
#d
prop.test(x=11, n=23, conf.level=0.95)
print(paste("Width of CI is", 0.6891538-0.2742042))
#e
prop.test(x=1, n=23, conf.level=0.95)
print(paste("Width of CI is", 0.239677815-0.002273764))
#=======================================
#Exercise 6.2
#=======================================
library("airquality")
#=======================================
#Exercise 6.2
#=======================================
install.packages("airquality")
library("airquality")
#=======================================
#Exercise 6.2
#=======================================
str(airquality)
airquality
head(airquality)
#=======================================
#Exercise 6.2
#=======================================
#no need to install package as it is already an existing dataframe in r
str(airquality)
dim(airquality)
str(airquality)
head(airquality)
dim(airquality)
wind = airquality[,3]
wind
head(airquality)
wind = subset(airquality,Month == 8 | Month == 9)
wind
augsep = subset(airquality,Month == 8 | Month == 9)
AugSep = subset(airquality,Month == 8 | Month == 9)
qqplot(AugSep[wind])
qqplot(AugSep[,3])
help(qqplot)
qqnorm(AugSep[,3])
qqline(AugSep[,3],col='red')
qqline(AugSep[,3],col='red')
qqnorm(AugSep[,3])
qqline(AugSep[,3],col='red')
AugSep = subset(airquality,Month == 8 | Month == 9)
AugSep
#IIb
#Method 1: normal approximation
x = AugSep[,3]
x
#IIb
#Method 1: normal approximation
x = AugSep[,3]
#Method 3: t-test
t.test(x, mu=10)
x = AugSep[,3]
n = length(x)
xbar = mean(x)
s = sd(x)
mu0 = 10
z = (xbar - mu0)/(s/sqrt(n))
pvalueNormal = 1- pnorm(z)
pvalueNormal
help(pnorm)
pvalueNormal = 2*pnorm(z)
pvalueNormal
#Method 2: t approximation
t = (xbar - mu0)/(s/sqrt(n))
pvalueT = 2*pt(t, df=n-1)
pvalueT
#Method 3: t-test
t.test(x, mu=10)
help(pt)
#Method 1: normal approximation
n = 25000
phat = 2700/25000
p0 = 0.1
p_value = 1 - pnorm((phat-p0)/sqrt(p0*(1-p0)/n))
p_value
#Method 2: prop.test
prop.test(2700,25000,0.1,alt='greater')
#=======================================
#Exercise 6.4
#=======================================
n = c(10,11,20,30)
type1error = 1 - pnorm(0.5*sqrt(n))
type1error
type2error = pnorm((0.5-mu)*sqrt(11))
mu = c(1,1.1,1.2,1.3)
type2error = pnorm((0.5-mu)*sqrt(11))
type2error
1-type2error
0.85/12
hwlp(glm)
help(glm)
help("predict")
install.packages("mlbench")
data(BreastCancer,package='mlbench')
dim(BreastCancer)
bc = BreastCancer[complete.cases(BreastCancer),]
BreastCancer
bc
head(bc)
head(bc,10)
str(bc)
x = as.numeric(bc$Cell.size)
y = ifelse(bc$Class == 'malignant',1,0)
plot(x,y,xlab='Cell.size',ylab='Class',pch=19)
y = factor(y, levels=c(0,1))
table(y)
help(factoir)
help(factor)
glm(y~x, family='binomial')
#PS0002 Tutorial 7
library('mlbench')
library('dplyr')
data(BreastCancer,package='mlbench')
str(BreastCancer)
bc = BreastCancer[complete.cases(BreastCancer),]
dim(bc)
help(apply)
help(sapply)
bc[,2:4] = sapply(as.numeric)
bc[,2:4] = sapply(bc[,2:4],as.numeric)
bc[,2:4]
BreastCancer
bc = bc %>% mutate(y=factor(ifelse(Class='malignant',1,0))) %>% select(Cl.thicness:Cl.shape,y)
library('dplyr')
bc = bc %>% mutate(y=factor(ifelse(Class='malignant',1,0))) %>% select(Cl.thicness:Cl.shape,y)
bc = bc %>% mutate(y=factor(ifelse(Class=='malignant',1,0))) %>% select(Cl.thicness:Cl.shape,y)
bc = bc %>% mutate(y=factor(ifelse(Class =='malignant',1,0))) %>% select(Cl.thickness:Cl.shape,y)
bc = bc %>% mutate(y=factor(ifelse(Class =='malignant',1,0))) %>% select(Cl.thickness:Cell.shape,y)
bc
str(bc)
set.seed(100)
training.idx = sample(1 : nrow(bc), size = nrow(bc)* 0.8)
train.data = bc[training.idx,]
test.data = bc[-training.idx,]
mlogit = glm(y~Cl.thickness + Cell.size + Cell.shape, data = train.data, familiy = 'binomial')
mlogit = glm(y~Cl.thickness + Cell.size + Cell.shape, familiy = 'binomial', data = train.data)
mlogit = glm(y~Cl.thickness + Cell.size + Cell.shape, family = 'binomial', data = train.data)
mlogit
summary(mlogit)
Pred.p = predict(mlogit,newdata = test.data, type = 'response')
y_pred_num = ifelse(Pred..p > 0.5, 1, 0)
y_pred_num = ifelse(Pred.p > 0.5, 1, 0)
y_pred = factor(y_pred_num, levels=c(0,1))
mean(y_pred == test.data$y)
tab = table(y_pred, test.data$y)
tab
df = data(iris)
dim(iris)
head(iris)
(x-min(x))/(max(x)-min(x))
head(iris)
nor= function(x){
(x-min(x))/(max(x)-min(x))
}
set.seed(100)
ran = sample(1:nrow(iris),0.9*nrow(iris))
iris_norm = as.data.frame(lapply(iris[,1:4],nor))
iris_norm
summary(iris_norm)
iris_train = iris_norm[ran,]
iris_test = iris_norm[-ran,]
iris_target_category = iris[ran,5]
iris_test_category = iris[-ran,5]
library(class)
pr = knn(iris_train,iris_test,cl=iris_target_category,k=13)
pr
help(knn)
iris_test_category
tab = table(pr,iris,iris_test_category)
tab = table(pr,iris_test_category)
tab
accuracy = function(x){
sum(diag(x))/(sum(rowSums(x))) * 100
}
accurary(tab)
accuracy(tab)
help(colnames)
help(col.names)
help(row.names)
help("rownames")
#4.2.3
#scatter plot
ggplot(data = newdataframe, aes(x = floor_area_sqm,y = log_resale_price)) + geom_point()
setwd("C:/Users/Asus/Desktop/mh3511project")
library(dplyr)
library(ggplot2)
dataframe = read.csv("mh3511data.csv",header=T)
head(dataframe)
#split the remaining_lease into two columns
library(stringr)
remaining_lease = dataframe[,10]
dataframe[c('years','NULL','months','NULL')] = str_split_fixed(dataframe$remaining_lease,' ',4)
newdataframe = dataframe[-c(10,13,15)]
#convert years and months into integer
newdataframe[,11:12] = sapply(newdataframe[,11:12], as.numeric)
str(newdataframe)#check datatype
newdataframe$months[is.na(newdataframe$months)] = 0
#create a new column: total_months
newdataframe = newdataframe %>% mutate(totalmonths = newdataframe$years * 12 + newdataframe$months)
#prepare log-e transformation of resale_price variable
newdataframe = newdataframe %>% mutate(log_resale_price = log(resale_price))
#prepare log-e transformation of floor_area_sqm
newdataframe = newdataframe %>% mutate(log_floor_area_sqm = log(floor_area_sqm))
#4.2.1
newdataframe %>% group_by(newdataframe$town) %>% summarise(count = n()) #get all group names
newdataframe = newdataframe %>% mutate(region=' ')
#apply categorical variable region (could have better method)
newdataframe$region[newdataframe$town == 'ANG MO KIO'] = 'Northern'
newdataframe$region[newdataframe$town == 'BEDOK'] = 'Eastern'
newdataframe$region[newdataframe$town == 'BISHAN'] = 'Northern'
newdataframe$region[newdataframe$town == 'BUKIT BATOK'] = 'Western'
newdataframe$region[newdataframe$town == 'BUKIT MERAH'] = 'Southern'
newdataframe$region[newdataframe$town == 'BUKIT PANJANG'] = 'Western'
newdataframe$region[newdataframe$town == 'BUKIT TIMAH'] = 'Central'
newdataframe$region[newdataframe$town == 'CENTRAL AREA'] = 'Central'
newdataframe$region[newdataframe$town == 'CHOA CHU KANG'] = 'Western'
newdataframe$region[newdataframe$town == 'CLEMENTI'] = 'Western'
newdataframe$region[newdataframe$town == 'GEYLANG'] = 'Eastern'
newdataframe$region[newdataframe$town == 'HOUGANG'] = 'Northern'
newdataframe$region[newdataframe$town == 'JURONG EAST'] = 'Western'
newdataframe$region[newdataframe$town == 'JURONG WEST'] = 'Western'
newdataframe$region[newdataframe$town == 'KALLANG/WHAMPOA'] = 'Central'
newdataframe$region[newdataframe$town == 'MARINE PARADE'] = 'Eastern'
newdataframe$region[newdataframe$town == 'PASIR RIS'] = 'Eastern'
newdataframe$region[newdataframe$town == 'PUNGGOL'] = 'Northern'
newdataframe$region[newdataframe$town == 'QUEENSTOWN'] = 'Southern'
newdataframe$region[newdataframe$town == 'SEMBAWANG'] = 'Northern'
newdataframe$region[newdataframe$town == 'SENGKANG'] = 'Northern'
newdataframe$region[newdataframe$town == 'SERANGOON'] = 'Northern'
newdataframe$region[newdataframe$town == 'TAMPINES'] = 'Eastern'
newdataframe$region[newdataframe$town == 'TOA PAYOH'] = 'Central'
newdataframe$region[newdataframe$town == 'WOODLANDS'] = 'Northern'
newdataframe$region[newdataframe$town == 'YISHUN'] = 'Northern'
newdataframe %>% group_by(region) %>% summarise(count=n())
#boxplot
ggplot(data = newdataframe, aes(x = region,y = log_resale_price)) + geom_boxplot()
#ANOVA test
summary(aov(newdataframe$log_resale_price~factor(newdataframe$region)))
pairwise.t.test(newdataframe$log_resale_price,newdataframe$region,p.adjust.method='none' )
###########################################
#4.2.2
#boxplot
ggplot(data = newdataframe, aes(x = flat_type,y = log_resale_price)) + geom_boxplot()
#ANOVA test
summary(aov(newdataframe$log_resale_price~factor(newdataframe$flat_type)))
pairwise.t.test(newdataframe$log_resale_price,newdataframe$flat_type,p.adjust.method='none' )
#4.2.3
#scatter plot
ggplot(data = newdataframe, aes(x = floor_area_sqm,y = log_resale_price)) + geom_point()
abline(0,1)
#4.2.3
#scatter plot
ggplot(data = newdataframe, aes(x = floor_area_sqm,y = log_resale_price)) + geom_point() + geom_smooth()
abline(0,1,col='red')
abline(lm(newdataframe$log_resale_price ~ newdataframe$floor_area_sqm), data = newdataframe)
abline(lm(newdataframe$log_resale_price ~ newdataframe$floor_area_sqm), data = newdataframe, col='blue')
#4.2.5
#linear model
model1 = lm(newdataframe$log_resale_price~newdataframe$remaining_lease)
newdataframe
#4.2.5
#linear model
model1 = lm(newdataframe$log_resale_price~newdataframe$totalmonths)
#4.2.5
#linear model
lmodel = lm(newdataframe$log_resale_price~newdataframe$totalmonths)
summary(lmodel1)
summary(lmodel)
#4.2.5
#linear model
ggplot(data = newdataframe, aes(x = totalmonths,y = log_resale_price)) + geom_point() + geom_smooth()
confint(lm(newdataframe$log_resale_price~newdataframe$totalmonths), level =0.95)
